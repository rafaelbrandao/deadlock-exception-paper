\chapter{Introduction}
\label{chp:introduction}

% \begin{quotation}[]{Poul Anderson}
% I have yet to see any problem, however complicated, which, when looked at in the
% right way, did not become still more complicated.
% \end{quotation}

Real-world applications use concurrency to take the more advantage of multicore processors and do computation in parallel using multiple threads/processes.
However concurrent code is difficult to write correctly, as it is well documented~\citep{lu}.
In a concurrent code, for example, a developer must take in consideration all possible interleaves that multiple threads in the running code can take which is usually not feasible, and when multiple threads read and write concurrently a certain value in memory, data races may occur.
Identifying parts of code that should not allow concurrent threads to run simultaneously is one step forward solving the problem.
These areas are known as critical sections and one way to prevent such data races is to protect them with locks.

Lock is a synchronization mechanism that enforce mutual exclusion policy over threads for any given resource.
Threads attempting to acquire a lock that was already acquired by other thread will be blocked until that resource is released. 
Only the owner of the lock can release that lock and unblock others, so usually a thread releases it when it finishes to execute code in a critical section, allowing other threads to proceed.
They are widely used to protect critical zones, thus avoiding data races in concurrent code.
However a problem introduced by badly composing locks is known as deadlock~\citep{pyla}.

Deadlocks are a very common type of error in concurrent systems~\citep{lu}.
They manifest when threads are waiting each other in a cycle, where each thread is waiting for another thread to release its desired lock, producing a never-ending wait.

There are two well-documented types of deadlocks, resource deadlocks and communication deadlocks~\citep{singhal}\citep{knapp}.
Resource deadlocks are deadlocks that stem from threads attempting to obtain exclusive access to resources.
Communication deadlocks are deadlocks caused by at least one thread waiting for any kind of signal that either never arrives or arrived too early to be detected.
As other studies did~\citep{mcsdk}\citep{magicfuzzer}, in this work our focus is also on resource deadlocks and whenever the term \emph{deadlock} is used we will implicitly mean resource deadlock.

In practice, developers employ a number of approaches to deal with deadlocks:
(i) static program analyses \citep{marino}\citep{dawson}\citep{vivek}\citep{williams};
(ii) dynamic program analyses \citep{mcsdk}\citep{magicfuzzer}\citep{sammati}\citep{serenity}\citep{pyla}\citep{rx};
(iii) application-specific deadlock detection infrastructu\-res \citep{orderedlock};
(iv) techniques to guarantee the absence of deadlocks by construction \citep{marino};
(v) model checking \citep{havelund}.
The first two approaches are known to be heavyweight. In addition, the former often produces many false positives.
The third approach has limited applicability and often imposes a high runtime overhead.
The fourth approach has a low cost but cannot be employed in cases where it is not feasible to order lock acquisitions nor use non-blocking locking primitives.
Finally, model checking is a powerful solution but has limited scalability when applied in the context of real programs. It also has limited generality, since some programs with side effects simply cannot be model checked.

In this paper we advocate an approach that complements the aforementioned ones.
In summary, we believe deadlocks should not fail silently but instead their occurrence should be signaled as exceptions at runtime.
To make this vision possible, we leverage two insights:
(i) the vast majority of existing deadlocks occur between two threads attempting to acquire two locks (as reported by other authors~\citep{lu} and confirmed by us in Section~\ref{bugs});
(ii) it is possible to efficiently introduce deadlock detection for these \ac{tttl} deadlocks within the locking mechanism itself, incurring in an overhead that is low for applications whose execution time is not dominated by locking.
We present a new type of lock that automatically checks for \ac{tttl} deadlocks at runtime and, if one is found, throws an exception indicating the problem.
We have implemented this approach as an extension to Java's {\tt ReentrantLock} class.
Deadlock exceptions are already supported in programming languages such as Haskell \citep{marlow} and Go \citep{golang} but they focus on different types of deadlocks, and runtime exceptions for other concurrency bugs, e.g., for data races, have been proposed in previous studies~\citep{valor}.

We present data from an empirical study showing that our assumption about the prevalence of \ac{tttl} deadlocks holds in practice. It confirms the findings of a previous study that focused on concurrency bugs in general~\citep{lu}. 
To evaluate our approach, we conducted two controlled experiments. In both cases, subjects using these new locks were able to detect deadlocks significantly faster than subjects not using them.  Furthermore, in one of the studies, this approach helped the subjects to more accurately identify the causes of the deadlock. We also show that our approach has an overhead that, while non-negligible, is low for applications whose execution time is not dominated by locking.

\section{Summary of Goals}

In this work we want to accomplish the following goals:
(i) verify that \ac{tttl} deadlocks are the most common type of deadlock in practice;
(ii) present a solution for \ac{tttl} deadlock detection that can be implemented with significantly low overhead;
and (iii) evaluate deadlock exceptions' impact on software development productivity, such as finding deadlocks in code and understanding how they happen more accurately.

\section{Outline}

In this introduction, we briefly contextualized the research and our motivation behind introducing deadlock runtime exceptions in programming languages
and how it is different from previous studies. The following chapters will go in more details about it:


% TODO: update this %
\begin{itemize}
\item
Chapter \ref{background} highlights previous studies regarding deadlock detection and why we believe it is important to have deadlock exceptions support in programming languages.
\item
Chapter \ref{bugs} presents our study on bug reports in open source projects, focusing on deadlock bugs and identifying some of its characteristics.
\item
Chapter \ref{protocol} shows our deadlock detection protocol, a sketch of a proof to support it, and explains what changes we did on Java's \emph{ReentrantLock} to support it.
\item
Chapter \ref{evaluation} discuss the empiric evaluation we did to measure efficiency of deadlock exceptions and a brief performance analysis of runtime overhead.
\item
Chapter \ref{conclusion} presents the contributions of this work, discusses some related and future work, and presents our main conclusions.
\item
Appendix follows complementing with all data we used for bug reports study and how we calculated experiments results.

\end{itemize}

%\item Appendix A shows the code used to calculate the size of sample we've used in Chapter 3.
%\item Appendix B shows the code used to analyse the data collected in Chapter 3.
%\item Appendix C shows the code used to collect the data from different repositories used in Chapter 3.
%\item Appendix E shows R instructions to evaluate time used in Chapter 5.
%\item Appendix F shows input for R script used to analyse time in Chapter 5.

