\chapter{Bug Reports Study}

In a previous study \cite{lu}, some interesting pattern about concurrency bugs was found: 30 out ot 31 deadlock cases involved at most two resources, where only one case was triggered by three threads waiting for three resources circularly. After that we also suspected that deadlocks between 2 threads and 2 resources are more common than other resource deadlocks, so we've decided to investigate this observation further with a bigger sample of real-world deadlock bug reports from open-source projects.

In this chapter, we'll present how we have conducted our bug reports study. We can split it in three parts: how we've collected the sample, how we've classified each bug in that sample, and what results we have found.

\section{Sample Collection}

We've chosen three open source projects which used Java as main programming language and made use of concurrent programming: Lucene, Eclipse and OpenJDK.

Lucene\footnote{Lucene: http://lucene.apache.org/} is a text search engine library that can be used along many applications, where concurrent programming was used to deliver high performance. Eclipse\footnote{Eclipse: https://eclipse.org/} is one of the most popular IDE for java developers. OpenJDK\footnote{OpenJDK: http://openjdk.java.net/} is an open-source implementation of the Java Platform. These three projects share a few similarities: they're written in Java; they have vast bug report repositories and tools to search for bug reports; development culture of reviews inside bug reports by discussing solutions to fix the problem. In particular, this last point is very important since we need to analyse bug reports and infer their classification.

We have initially searched in each repository for the keyword \emph{deadlock}, and we've collected 541 bug reports in total. Each project had a different bug repository, so we've changed slightly the query parameters to find relevant bug reports.

In Lucene, we've searched for bugs matching the word "deadlock" anywhere in the bug report (i.e. in summary or in comments), in module "lucene-core" with issue type as "bug", where status was "closed". From this search, we've found 27 bugs\footnote{http://goo.gl/DhVI3t}.

In Eclipse, we've searched for "deadlock" in summary, where resolution was set to "fixed" and status was set to "resolved". From this search, we've found 406 bugs\footnote{http://goo.gl/qQnrEm}.

In OpenJDK, we've searched the word "deadlock" in summary, in module "JDK" with issue type as "bug", where resolution was set to "fixed", status was "resolved". From this search, we've found 108 bugs\footnote{http://goo.gl/xYFfsO}.

Assuming normal distribution in bug reports population, we've calculated the minimal size of the sample where we could achieve 95\% of confidence level and 5\% sampling error (also setting response distribution to 50\% to find the biggest sample size\footnote{More about 'response distribution' in http://www.raosoft.com/samplesize.html}). We've found minimal size as 225, so we've created a random sample of 225 bugs out of all bugs we've found. In appendix we provide the code we've used to calculate the sample size.

\section{Data Labeling}

We've merged all bug reports of our random sample in one single table. The first field was the name of the bug, each name was composed by a prefix that could be either \emph{LUCENE}, \emph{ECLIPSE} or \emph{JDK}, followed by the bug number inside its own repository. Then we've added a category label field which could be "A", "B", "C" or "D". The category was added after manual inspections based on criterias that we will present next. Furthermore we've added other fields in this table such as \emph{"TYPE"}, \emph{"# of THREADS"}, \emph{"# of RESOURCES"} and \emph{"NOTES"}, they'll be described next.

The final version of this table\footnote{http://goo.gl/zNsIGz} also contains \emph{"TIME (HOURS)"} and \emph{"COMMENTS"}, but these were extracted automatically from the bug reports data and we did not use them for this analysis.

\subsection{Field "CATEGORY"}

This is one of the most important fields, as we want to be able to identify what kind of deadlock this bug represents, or if it's not even a real deadlock. We have four different values for this field, and they must be one of the following:

\emph{A:} We are confident this a resource deadlock. We should be able to provide a short explanation of how the bug occurs, which or how many threads are involved and how many locks are involved in this bug.

\emph{B:} We are confident this is not a resource deadlock, so it must be a communication deadlock. It might be a lost notify/signal bug. We should be able to identify if this is a lost notify/signal or have clear evidence this is not a resource deadlock (adding a note whenever possible).

\emph{C:} We are confident this is a false-positive for "deadlock" search. The term was used as a synonym of "hang" or "infinite loop", or to refer to another deadlock bug. In some cases, it is possible that a bug refers to another bug which was fixing a deadlock, so the initial bug may not be deadlock-related and just fix a regression for another bug (which could be deadlock-related). In other words, this is not a deadlock bug at all.

\emph{D:} We are not confident whether this is a resource deadlock or a communication deadlock, or even if this is a false-positive for deadlock. There's not enough information in the bug report, or the information is just inconclusive. Since we are not experts on any of these repositories, it's hard to classify for sure in another category.

Category A will be only assigned when there's a clear comment in the bug explaining what threads and which resources are involved or other evidences can clarify without doubt how many threads and lock resources are involved. In a few cases, the explanation is not fully clear but the attachment provides a clear thread dump showing which threads are involved and which locks each one is holding and waiting for, so we can also use this information to make a final decision.

Category B can be classified by also looking into source code changes when we are almost clear about its category: if the patch changes areas of the code where a notifyAll is added or moved, then it is most likely a category B indeed. Sometimes it is just a semantic deadlock where one threads is in an infinite loop waiting for others to finish and other threads are stuck waiting to acquire a lock the first thread already acquired; in this case, we also understand as a communication deadlock: the "message" which the first thread have been waiting is whether the other threads have finished.

Category C is often easy to classify since the bug often explains another kind of bug and then cites the term "deadlock" as a synonym for "hang". As stated previously, if this bug only refers to another bug (such as a regression) that mentions deadlock or fixes a deadlock, then this bug might not be a deadlock by itself, just a fix of another previous fix, which would also fall into this category.

Category D is for all other bugs which could not be classified as either A, B or C.

\subsubsection{Reviewing Protocol:} 

In order to minimize error on our classification, we've created a protocol that every reviewer should follow, which basically describes how data should be analysed for a certain bug. For example, sometimes a bug points to another one as a duplicate, those links should be used if the initial bug is not clear enough. In order to organize how the review is executed, we should roughly follow these steps:

1. Look at bug title and bug main description (usually the first comment). Sometimes the reporter have an idea of how the bug occurs and which threads are involved, so this is a big help.

2. Look at further comments and see if someone understood this bug completely. Someone must have provided a reasonable explanation of how this bug occurs. If the category is already clear, then finish these steps; otherwise proceed.

3. If available, look at the patches (specially the final patch) and what changes have been made. If uncertain about this bug being in category B and the patch either moves or adds a notifyAll call, then it most likely is a category B bug. If this is not the case, then proceed.

4. If available, look at the related bugs or duplicates. It's often to find an initial bug that is unclear but which points out to a duplicate that have been largely discussed and is clear. Restart from step 1 for each of those related bugs. If a category was not assigned yet, then proceed.

5. See other attachments if available, like text files with thread dumps or stack traces. If they provide enough information to clarify which category it is, then assign a category to it, otherwise proceed.

6. Classify this bug in the category D.


\subsection{Fields "\# of THREADS" and "\# of RESOURCES"}

Whenever possible, the reviewer should state the number of threads and resources involved, even if this is in the category B. If it's unknown how many resources but it is clear how many threads are involved, then only one of them should be filled and the other field should remain blank.

\subsection{Field "TYPE"}

This field is just an annotation and it should be used to specify what kinds of resources a certain bug use. For example if there are two threads and they're in a circular deadlock, then this field should be locks/synchronized, or if you are sure that explicit locks were used for both, then just locks is enough, or if only synchronized blocks/methods are involved, then just synchronized.

The symbol + indicates a separation between threads, so for example "locks + wait" means that one thread holds a lock and the other waits". As this may be confusing, an easy replacement would be to use the "notes" field instead and write down what was found about this bug.

\subsection{Field "NOTES"}

This field was encouraged to be used specially to remind other reviewers in the future of how the conclusion was made for cases where it was tricky to choose the category.

\section{Results Analysis}

As we want to understand how many resource deadlock bugs did involve 2 threads and 2 resources, we discard bugs in B and C category because they're not resource deadlocks. What we have left are the bugs we could not determine its category. In the worse case scenario, all bugs in category D should be resource deadlocks which would involve something different than 2 threads and 2 resources, given by the following equation:

\begin{equation}
bugs\_ratio = \frac{ bugs(A, threads=2, resources=2) }{ bugs(A) + bugs(D) } \; .
\end{equation}

In that equation, \emph{bugs(...)} returns the number of bug reports that matches the parameters. Thus $bugs\_ratio$ represents the worse case scenario. However if we want to look at the best case scenario, then all bugs classified in D category must also be classic resource deadlocks.

\begin{table}
\begin{center}
\caption{Bug Reports Classification.}
\begin{tabular}{|l|l|}
\hline
Category & Number of Bugs \\
\hline
A & 101 \\   
B & 32 \\
C & 23 \\
D & 69 \\
\hline
\end{tabular}
\end{center}
\end{table}

The numbers we've found are 54.7\% in the worse case and 95.29\% on the best case. In category A, we've found 93 bugs of classic deadlocks. That means \textbf{from all resource deadlocks we've found, 92.07\% of them were classic deadlocks}, which corroborates with the finding of study conducted by Lu, Shan, et al \cite{lu}. Also, \textbf{75.93\% of deadlock bugs were classified as resource deadlocks} which shows how popular resource deadlocks are in comparison to communication deadlocks.

We can also look at bugs in category D differently and assume that their distribution will follow the proportions of bugs we've found for A, B and C. We can do the same for bugs inside category A.

When we reclassify all bugs in D in other categories, we'll have the following: 45 new bugs in A where 41 bugs should also be classic deadlocks; 14 new bugs in B; and 10 new bugs in C. We can see the updated values in the following table.

\begin{table}
\begin{center}
\caption{Bug Reports Categories Proportionally Distributed.}
\begin{tabular}{|l|l|}
\hline
Category & Number of Bugs \\
\hline
A & 146 \\   
B & 46 \\
C & 33 \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{equation}
bugs\_ratio = \frac{ [ bugs(A, threads=2, resources=2) = 134 ] }{ [bugs(A) = 146] + [bugs(D) = 0] } \; .
\end{equation}

Running the same equation again with the new values, \textbf{we estimate that 91.7\% of resource deadlocks should be classic deadlocks if we could predict bug categories in D}.

\section{Findings}

As we've highlighted in the previous section, classic deadlocks are by far the most popular type of resource deadlocks; also, resource deadlocks are more popular than communication deadlocks. This gives us evidence that if we can solve the problem of deadlock detection for the classical case, that is, between 2 threads and 2 locks, we can cover most of the bugs.

We believe that giving developers a signal that something is wrong in the code (i.e. an exception) is much more powerful than showing nothing (as it happens today). Exceptions provide an easy framework to reason about potential issues in the code and makes easier to handle bugs once they were detected. And even if the bug is not handled, it still gives a signal to developers that something is wrong and should be fixed.

In the next chapter, we will present our deadlock detection algorithm we've built that will throw an exception when a classical deadlock happens. Following that chapter, we will show an experiment we did with students to test whether these exceptions are indeed helpful to find problems in the code.

