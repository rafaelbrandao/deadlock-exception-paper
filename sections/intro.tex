\chapter{Introduction}

Real-world applications use concurrency to parallelize computation in multiple threads or processes, taking more advantage of multicore processors.
However concurrenct code is difficult to write correctly, as it is well documented in \cite{lu}. In a concurrent code, for example, a developer must
take in consideration all possible interleaves that multiple threads in the running code can take which is simply not feasible.
When multiple threads access concurrently a certain memory position, data races may occur.
One way to solve this problem is to first identify parts of the code that should not allow threads to run simultaneously -- they are
called critical sections -- and then protect them by using locks. 

Locks are used to avoid data races in concurrent code. When a thread acquires a certain lock, no other thread can acquire the same lock.
Any thread that attempt to acquire that lock will be blocked until that resource is released. Once that thread finishes to execute critical code,
it should release that lock so other threads would be unblocked afterwards.

Unfortunately locks cannot be easily composed in the code and a very common bug caused by composing locks in unexpected ways is called deadlock.
A deadlock manifests when threads are waiting each other in a cycle, each one holding locks that other thread is trying to acquire.

Suppose a thread X acquires a lock A and then tries to acquire a lock B. Given the nature of parallelism, another thread Y simultaneously acquires
a lock B and then tries to acquire lock A. Since thread X is blocked waiting for lock B to be released and thread Y which owns lock B is blocked
waiting for thread X to release lock A, both will never finish waiting, thus creating a deadlock. When a deadlock happens, a program fail
to make progress without notice to users and developers, making harder to identify the problem.

Deadlocks can be avoided if locks are acquired in any order, as long as the other threads follows that particular order. For example, if both thread X
and thread Y always acquired locks A and B in this order, then no deadlock could ever occur because there's no waiting relationship cycle between them. 
Some existing techniques to avoid deadlock require to impose a global order on locks and check whether this order is ever violated when the locks are acquired \cite{marino},
but this approach is not practical for real world software because most of the time the code that acquires the first lock is unaware of wh.

There are two main types of deadlocks: resource deadlocks and communication deadlocks \cite{singhal} \cite{knapp}. Resource deadlocks are illustrated in the previous
example, where threads wait for resources to become available. Communication deadlocks happens when threads are blocked waiting messages, so messages are the resources
for which threads wait. In this work, as other studies did before \cite{mcsdk} \cite{magicfuzzer}, our focus will be on resource deadlocks and from now on and whenever the term \emph{deadlock} is used by itself we will be referring to resource deadlocks unless mentioned otherwise.

Over the time, many studies tried to solve deadlock by detecting them in many different ways which can be made by either static analysis, dynamic analysis, or a mix of them. Static analysis leverage deadlock existence by reading the source code and estimating whether a deadlock would be possible with that code without actually running it. In counter part, dynamic analysis dynamically add extra code in the original source and possibly detect real deadlocks during execution. But each one of those techniques
have its own advantages and disadvantages and they complement one another.

In this study, however, we are focusing on solving deadlocks differently. We believe deadlocks should not fail silently but instead they should be handled as exceptions in programming languages. Rather than trying to detect them when explicitly requested for a deadlock analysis, programs should instead be written in such a way that they can either handle the deadlock when it happens by deploying some custom deadlock recovery logic or just show the error in the output in order to ease finding bugs and solving them later.

There are some programming languages such as Haskell and Go that already contain some kind of deadlock exception for very particular cases. In this study, the proposed deadlock exception was focused on what we've found out to be the most common type of deadlock: the classical deadlock illustrated in the previous example where only two threads are involved and they're waiting circularly for two resources.

\section{Summary of Goals}

In this work we have the main goal to show how deadlock detection between two threads and two locks can be implemented with very low runtime overhead and evaluate the impact of deadlock exceptions on the efficiency of identifying deadlocks in software by running an empirical study with students. With this contribution, we seek to understand the benefits of such exceptions in programming languages and also offer a lightweight implementation of deadlock exceptions that can seamlessly run on top of Java OpenJDK.

\section{Outline}

The remainder of this work will be organized as follows:

\begin{itemize}
  \item Chapter 2 discuss the basic concepts of deadlock exceptions, highlighting previous studies and terms that are necessary to understand before proceeding to the next chapters.
  \item Chapter 3 presents our study on bug reports in open source projects, focusing on deadlock bugs and identifying some of its characteristics.
  \item Chapter 4 shows our deadlock detection algorithm in details, presenting a sketch of a formal proof, what changes were done to Java's ReentrantLock and a quick performance evaluation.
  \item Chapter 5 discuss the empiric evaluation we did to measure efficiency of deadlock exceptions on identifying bugs in software.
  \item Chapter 6 presents the contributions of this work, discusses some related and future work, and presents our main conclusions.
  \item Appendix A shows the code used to calculate the size of sample we've used in Chapter 3.
  \item Appendix B shows the code used to analyse the data collected in Chapter 3.
  \item Appendix C shows the code used to collect the data from different repositories used in Chapter 3.
  \item Appendix D shows Java's ReentrantLock pseudocode cited in Chapter 4.
  \item Appendix E shows R instructions to evaluate time used in Chapter 5.
  \item Appendix F shows input for R script used to analyse time in Chapter 5.
\end{itemize}



